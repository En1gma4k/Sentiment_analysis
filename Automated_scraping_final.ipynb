{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd9d6ad",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5eb180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import io "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005d67e",
   "metadata": {},
   "source": [
    "### Reading the Input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16d63a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3        40  https://insights.blackcoffer.com/will-machine-...\n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...\n",
       "..      ...                                                ...\n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...\n",
       "110     147  https://insights.blackcoffer.com/the-future-of...\n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...\n",
       "112     149  https://insights.blackcoffer.com/business-anal...\n",
       "113     150  https://insights.blackcoffer.com/challenges-an...\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = pd.read_excel('C:/Users/milan/Desktop/BlackCoffer/input.xlxs')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c349de21",
   "metadata": {},
   "source": [
    "### Extracting article title and the article text and saving them to txt file with URL ID as file name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff7b53d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Fetched Successfully  0\n",
      "Data Fetched Successfully  1\n",
      "Data Fetched Successfully  2\n",
      "Data Fetched Successfully  3\n",
      "Data Fetched Successfully  4\n",
      "Data Fetched Successfully  5\n",
      "Data Fetched Successfully  6\n",
      "Data Fetched Successfully  8\n",
      "Data Fetched Successfully  9\n",
      "Data Fetched Successfully  10\n",
      "Data Fetched Successfully  11\n",
      "Data Fetched Successfully  12\n",
      "Data Fetched Successfully  13\n",
      "Data Fetched Successfully  14\n",
      "Data Fetched Successfully  15\n",
      "Data Fetched Successfully  16\n",
      "Data Fetched Successfully  17\n",
      "Data Fetched Successfully  18\n",
      "Data Fetched Successfully  19\n",
      "Data Fetched Successfully  21\n",
      "Data Fetched Successfully  22\n",
      "Data Fetched Successfully  23\n",
      "Data Fetched Successfully  24\n",
      "Data Fetched Successfully  25\n",
      "Data Fetched Successfully  26\n",
      "Data Fetched Successfully  27\n",
      "Data Fetched Successfully  28\n",
      "Data Fetched Successfully  29\n",
      "Data Fetched Successfully  30\n",
      "Data Fetched Successfully  31\n",
      "Data Fetched Successfully  32\n",
      "Data Fetched Successfully  33\n",
      "Data Fetched Successfully  34\n",
      "Data Fetched Successfully  35\n",
      "Data Fetched Successfully  36\n",
      "Data Fetched Successfully  37\n",
      "Data Fetched Successfully  38\n",
      "Data Fetched Successfully  39\n",
      "Data Fetched Successfully  40\n",
      "Data Fetched Successfully  41\n",
      "Data Fetched Successfully  42\n",
      "Data Fetched Successfully  43\n",
      "Data Fetched Successfully  44\n",
      "Data Fetched Successfully  45\n",
      "Data Fetched Successfully  46\n",
      "Data Fetched Successfully  47\n",
      "Data Fetched Successfully  48\n",
      "Data Fetched Successfully  49\n",
      "Data Fetched Successfully  50\n",
      "Data Fetched Successfully  51\n",
      "Data Fetched Successfully  52\n",
      "Data Fetched Successfully  53\n",
      "Data Fetched Successfully  54\n",
      "Data Fetched Successfully  55\n",
      "Data Fetched Successfully  56\n",
      "Data Fetched Successfully  57\n",
      "Data Fetched Successfully  58\n",
      "Data Fetched Successfully  59\n",
      "Data Fetched Successfully  60\n",
      "Data Fetched Successfully  61\n",
      "Data Fetched Successfully  62\n",
      "Data Fetched Successfully  63\n",
      "Data Fetched Successfully  64\n",
      "Data Fetched Successfully  65\n",
      "Data Fetched Successfully  66\n",
      "Data Fetched Successfully  67\n",
      "Data Fetched Successfully  68\n",
      "Data Fetched Successfully  69\n",
      "Data Fetched Successfully  70\n",
      "Data Fetched Successfully  71\n",
      "Data Fetched Successfully  72\n",
      "Data Fetched Successfully  73\n",
      "Data Fetched Successfully  74\n",
      "Data Fetched Successfully  75\n",
      "Data Fetched Successfully  76\n",
      "Data Fetched Successfully  77\n",
      "Data Fetched Successfully  78\n",
      "Data Fetched Successfully  79\n",
      "Data Fetched Successfully  80\n",
      "Data Fetched Successfully  81\n",
      "Data Fetched Successfully  82\n",
      "Data Fetched Successfully  83\n",
      "Data Fetched Successfully  84\n",
      "Data Fetched Successfully  85\n",
      "Data Fetched Successfully  86\n",
      "Data Fetched Successfully  87\n",
      "Data Fetched Successfully  88\n",
      "Data Fetched Successfully  89\n",
      "Data Fetched Successfully  90\n",
      "Data Fetched Successfully  91\n",
      "Data Fetched Successfully  92\n",
      "Data Fetched Successfully  93\n",
      "Data Fetched Successfully  94\n",
      "Data Fetched Successfully  95\n",
      "Data Fetched Successfully  96\n",
      "Data Fetched Successfully  97\n",
      "Data Fetched Successfully  98\n",
      "Data Fetched Successfully  99\n",
      "Data Fetched Successfully  100\n",
      "Data Fetched Successfully  101\n",
      "Data Fetched Successfully  102\n",
      "Data Fetched Successfully  103\n",
      "Data Fetched Successfully  104\n",
      "Data Fetched Successfully  105\n",
      "Data Fetched Successfully  106\n",
      "Data Fetched Successfully  108\n",
      "Data Fetched Successfully  109\n",
      "Data Fetched Successfully  110\n",
      "Data Fetched Successfully  111\n",
      "Data Fetched Successfully  112\n",
      "Data Fetched Successfully  113\n"
     ]
    }
   ],
   "source": [
    "url = inputs['URL']\n",
    "i = 0\n",
    "j = 0\n",
    "for i in range(len(url)):\n",
    "    ua = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "    page = requests.get(url[i], headers={\"User-Agent\": ua})\n",
    "    if(page.status_code==200):\n",
    "        print (\"Data Fetched Successfully \",i)\n",
    "        soup = BeautifulSoup(page.content,'html.parser')\n",
    "        article = ''\n",
    "        data = ''\n",
    "        for data in soup.find_all(\"p\"):  #to find all paragraphs\n",
    "            s = (data.get_text())\n",
    "            article = article +\" \" + s  #adding all the individual paragraphs into one article          \n",
    "  \n",
    "    name=str(inputs['URL_ID'][j])\n",
    "    with io.open(f'{name}.txt','w',encoding='utf8') as f:\n",
    "        f.write(article)\n",
    "    j=j+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b04eb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
